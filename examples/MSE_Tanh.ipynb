{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15c03fc5-59ab-412f-aa41-78c7bddd060f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea3b7327-1255-4dfa-aa60-00abdc0a6cc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/trinity/home/daria.cherniuk/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import USPS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# from autograd import grad, jacobian\n",
    "# import autograd.numpy as np\n",
    "from functools import partial\n",
    "from scipy.optimize import line_search\n",
    "\n",
    "from source.models import AE_ReLU, AE_Sigm, AE_Tanh\n",
    "from source.data import get_train_test_dataloaders\n",
    "from source.eval import eval_loss\n",
    "\n",
    "from functools import partial\n",
    "import copy\n",
    "import math\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "# from multiprocessing import Pool\n",
    "import torch.multiprocessing as mp\n",
    "from collections import OrderedDict\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ec66c9a-7d85-492b-84b0-6208751bf4e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_progress(x, z):\n",
    "    rows = 2\n",
    "    cols = 16\n",
    "    x, z = x[:cols], z[:cols]\n",
    "    fig, ax = plt.subplots(rows, cols, sharex=True, sharey=True, figsize=(cols, rows))\n",
    "    for i in range(len(x)):\n",
    "        # ax[i//cols, i%cols].imshow(x[i].cpu().reshape([16, 16]), 'gray')\n",
    "        # ax[i//cols, i%cols].set_axis_off()\n",
    "        ax[0, i].imshow(x[i].cpu().reshape([16, 16]), 'gray')\n",
    "        ax[0, i].set_axis_off()\n",
    "    for i in range(len(z)):\n",
    "        # ax[i//cols+2, i%cols].imshow(z[i].detach().cpu().numpy().reshape([16, 16]), 'gray')\n",
    "        # ax[i//cols+2, i%cols].set_axis_off()\n",
    "        ax[1, i].imshow(z[i].detach().cpu().numpy().reshape([16, 16]), 'gray')\n",
    "        ax[1, i].set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "decd02c7-dfc7-4ddb-ac28-1737f518d89c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, test_loader = get_train_test_dataloaders('..', 'USPS', \n",
    "                                                       batch_size=7291, \n",
    "                                                       drop_last=False,\n",
    "                                                       num_workers=4)\n",
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48cd8881-574c-4172-923d-f5dddd02f6ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dcf9c10-d794-43ff-b7c8-7c0ee1283651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def softmax(a):\n",
    "#     result = np.exp(a)\n",
    "#     return result / result.sum()\n",
    "\n",
    "# a = torch.tensor([1,2,3,4], dtype=torch.float)\n",
    "# softmax(a), torch.nn.functional.softmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f7423f7-85cb-4596-ab08-348915ff2aa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# softmax_grad = jacobian(softmax)\n",
    "# softmax_grad(np.array([1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b3d1ac0-3075-423a-9932-319c4642ba3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bk=torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da0746a2-a3fc-46bc-b7af-177fed39dee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def w_residuals(w_h, layer_idx, h, x, CACHE_RELUS):\n",
    "    \n",
    "    if layer_idx == 0:\n",
    "        residuals = CACHE_RELUS[layer_idx][:,h] - torch.tanh(x @ w_h)\n",
    "    elif layer_idx == len(CACHE_RELUS):\n",
    "        residuals = x[:,h] - torch.tanh(CACHE_RELUS[layer_idx-1] @ w_h)\n",
    "    else:\n",
    "        residuals = CACHE_RELUS[layer_idx][:,h] - torch.tanh(CACHE_RELUS[layer_idx-1] @ w_h)\n",
    "        \n",
    "    return residuals\n",
    "\n",
    "def w_f(w_h, layer_idx, h, x, CACHE_RELUS):\n",
    "    \n",
    "    squares = torch.square(w_residuals(w_h, layer_idx, h, x, CACHE_RELUS))\n",
    "    return squares.sum() / 2\n",
    "\n",
    "def w_jacob(w_h, layer_idx, n_samples, x, CACHE_RELUS):\n",
    "    J = torch.zeros((n_samples, len(w_h)), device=device)\n",
    "\n",
    "    if layer_idx == 0:\n",
    "        for n in range(n_samples):\n",
    "            J[n, :] = -(1 - torch.square(torch.tanh(x[n] @ w_h))) * x[n]\n",
    "    else:\n",
    "        for n in range(n_samples):\n",
    "            print\n",
    "            J[n, :] = -(1 - torch.square(torch.tanh(CACHE_RELUS[layer_idx-1][n] @ w_h))) * CACHE_RELUS[layer_idx-1][n]\n",
    "            \n",
    "    plt.spy(J.cpu().numpy())\n",
    "                \n",
    "    return J\n",
    "\n",
    "def w_step(w_h, layer_idx, h, n_samples, x, CACHE_RELUS):\n",
    "    \n",
    "    residuals = w_residuals(w_h, layer_idx, h, x, CACHE_RELUS)\n",
    "\n",
    "    # Building Jacobian (for each layer and output dim)\n",
    "    J = w_jacob(w_h, layer_idx=layer_idx, n_samples=n_samples, x=x, CACHE_RELUS=CACHE_RELUS)\n",
    "    \n",
    "    # why not inversion here?\n",
    "    p = bk.linalg.lstsq(J.T@J, - J.T @ residuals, rcond=None)[0]\n",
    "    # p.T @ grad (.T doesn't matter, numpy performs inner product)\n",
    "    descent_inner_prod = (J.T @ residuals) @ p\n",
    "    try:\n",
    "        assert descent_inner_prod <= 0\n",
    "    except:\n",
    "        # pass\n",
    "        print(f'layer {layer_idx+1} dim {h} descent(should be <= 0)', descent_inner_prod)\n",
    "\n",
    "    # Line Search with Backtracking\n",
    "    # w_grad = grad(partial(w_f, layer_idx=layer_idx, h=h, \n",
    "    #                       x=x, CACHE_RELUS=CACHE_RELUS))\n",
    "    # alpha = line_search(\n",
    "    #     partial(w_f,\n",
    "    #             x=x,\n",
    "    #             layer_idx=layer_idx,\n",
    "    #             h=h,\n",
    "    #             CACHE_RELUS=CACHE_RELUS),\n",
    "    #     w_grad,\n",
    "    #     w_h,\n",
    "    #     pk=p,\n",
    "    # )[0]\n",
    "    \n",
    "    # how to tweak it? \n",
    "    alpha = 10.0\n",
    "    f = w_f(w_h, layer_idx, h, x, CACHE_RELUS)\n",
    "    # First Update\n",
    "    f_new = w_f(w_h + alpha*p, layer_idx, h, x, CACHE_RELUS)\n",
    "    rhs = alpha * line_search_c * descent_inner_prod\n",
    "\n",
    "    max_iter, counter = 40, 0\n",
    "    # Armijo Condition\n",
    "    while f_new - f > rhs and counter < max_iter:\n",
    "        alpha *= line_search_tau\n",
    "        # Update\n",
    "        f_new = w_f(w_h + alpha*p, layer_idx, h, x, CACHE_RELUS)\n",
    "        rhs = alpha * line_search_c * descent_inner_prod\n",
    "\n",
    "        # print(\"Line search armijo: obj func old: %f new: %f diff: %.16f rhs: %.16f, alpha: %f\" % (f, f_new, f_new - f, rhs, alpha))\n",
    "        counter += 1\n",
    "        \n",
    "    if counter == max_iter:\n",
    "        print(f'Layer {layer_idx}: reached maximum number of iterations for line search')\n",
    "        \n",
    "    # print('alpha:', alpha)\n",
    "        \n",
    "    return w_h + alpha * p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05de38de-2a33-47ac-badc-8d249c831e68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def z_residuals(z_n, h_k, mu, x, WEIGHTS):\n",
    "    \n",
    "    residuals = torch.zeros(h_k[-1], device=device)\n",
    "    start = 0\n",
    "    for layer_idx in range(len(h_k)):\n",
    "        if layer_idx == 0:\n",
    "            residuals[start:h_k[layer_idx]] = z_n[start:h_k[layer_idx]] - bk.tanh(WEIGHTS[layer_idx] @ x)\n",
    "        elif layer_idx == 1:\n",
    "            residuals[start:h_k[layer_idx]] = z_n[start:h_k[layer_idx]] \\\n",
    "                                              - bk.tanh(WEIGHTS[layer_idx] @ z_n[:h_k[layer_idx-1]])\n",
    "        elif layer_idx == len(h_k):\n",
    "            residuals[start:h_k[layer_idx]] = x - bk.tanh(WEIGHTS[layer_idx] @  z_n[h_k[layer_idx-2]:h_k[layer_idx-1]])\n",
    "        else:\n",
    "            residuals[start:h_k[layer_idx]] = z_n[start:h_k[layer_idx]] \\\n",
    "                                              - bk.tanh(WEIGHTS[layer_idx] @ z_n[h_k[layer_idx-2]:h_k[layer_idx-1]])\n",
    "        start = h_k[layer_idx]\n",
    "        \n",
    "    # is it needed? \n",
    "    mu_mult = torch.ones_like(residuals)\n",
    "    mu_mult[:h_k[-2]] = math.sqrt(mu)\n",
    "    residuals = mu_mult * residuals\n",
    "    \n",
    "    return residuals\n",
    "\n",
    "def z_f(z_n, mu, h_k, x, WEIGHTS):\n",
    "    \n",
    "    squares = bk.square(z_residuals(z_n, h_k, mu, x, WEIGHTS))\n",
    "    return squares.sum() / 2\n",
    "\n",
    "def z_step(z_n, n_sample, mu, h_k, x, WEIGHTS):\n",
    "    \n",
    "    # Calculating Residuals\n",
    "    residuals = z_residuals(z_n, h_k, x, WEIGHTS)\n",
    "    assert len(residuals) == h_k[-1]\n",
    "\n",
    "    # Building Jacobian for each sample in dataset\n",
    "    z_grad = jacobian(partial(z_residuals, h_k=h_k, mu=mu, x=x, WEIGHTS=WEIGHTS))\n",
    "    J = z_grad(z_n)\n",
    "    \n",
    "    print(J.shape, residuals.shaoe)\n",
    "\n",
    "    # Descent Direction\n",
    "    p = torch.linalg.lstsq(J.T@J, - J.T @ residuals, rcond=None)[0]\n",
    "    # p.T @ grad (.T doesn't matter, numpy performs inner product)\n",
    "    descent_inner_prod = (J.T @ residuals) @ p\n",
    "    try:\n",
    "        assert descent_inner_prod <= 0\n",
    "    except:\n",
    "        print(f'sample {n_sample} descent direction should be <= 0', descent_inner_prod)\n",
    "\n",
    "    # Line Search with Backtracking\n",
    "    # p_ = torch.zeros(h_k[-1])\n",
    "    # p_[:h_k[-2]] = p\n",
    "    alpha = 10.0\n",
    "    f = z_f(z_n, mu, h_k, x, WEIGHTS)\n",
    "    f_new = z_f(z_n + alpha * p, mu, h_k, x, WEIGHTS)\n",
    "    rhs = alpha * line_search_c * descent_inner_prod\n",
    "\n",
    "    max_iter, counter = 40, 0\n",
    "    # Armijo Condition\n",
    "    while f_new - f > rhs and counter < max_iter:\n",
    "        # step update\n",
    "        alpha *= line_search_tau\n",
    "\n",
    "        f_new = z_f(z_n + alpha * p, mu, h_k, x, WEIGHTS)\n",
    "        rhs = alpha * line_search_c * descent_inner_prod\n",
    "\n",
    "        # print(\"Line search armijo: obj func old: %f new: %f diff: %.16f rhs: %.16f, alpha: %f\" % (f, f_new, f_new - f, rhs, alpha))\n",
    "        counter += 1\n",
    "        \n",
    "    # if counter == max_iter:\n",
    "    #     print(f'Layer {layer_idx}: reached maximum number of iterations for line search')\n",
    "    \n",
    "    \n",
    "    print('alpha:', alpha)\n",
    "     \n",
    "    return J, z_n + alpha * p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99eeab91-9015-47c5-9304-90446c75c3ef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random-initialized model loss: 0.16305185357729593\n",
      "[300, 400, 420, 520, 820]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 1 dim 3 descent(should be <= 0) tensor(8.1689, device='cuda:0')\n",
      "layer 1 dim 20 descent(should be <= 0) tensor(97.1562, device='cuda:0')\n",
      "layer 1 dim 20 descent(should be <= 0) tensor(98.5938, device='cuda:0')\n",
      "layer 1 dim 39 descent(should be <= 0) tensor(4.5757, device='cuda:0')\n",
      "layer 1 dim 46 descent(should be <= 0) tensor(1.7012, device='cuda:0')\n",
      "layer 1 dim 48 descent(should be <= 0) tensor(5.6094, device='cuda:0')\n",
      "layer 1 dim 51 descent(should be <= 0) tensor(5.0742, device='cuda:0')\n",
      "layer 1 dim 51 descent(should be <= 0) tensor(4.7070, device='cuda:0')\n",
      "layer 1 dim 51 descent(should be <= 0) tensor(4.8398, device='cuda:0')\n",
      "layer 1 dim 66 descent(should be <= 0) tensor(0.8862, device='cuda:0')\n",
      "layer 1 dim 71 descent(should be <= 0) tensor(285.1250, device='cuda:0')\n",
      "layer 1 dim 71 descent(should be <= 0) tensor(285.2500, device='cuda:0')\n",
      "layer 1 dim 71 descent(should be <= 0) tensor(286.1250, device='cuda:0')\n",
      "layer 1 dim 93 descent(should be <= 0) tensor(8.4492, device='cuda:0')\n",
      "layer 1 dim 93 descent(should be <= 0) tensor(8.3301, device='cuda:0')\n",
      "layer 1 dim 93 descent(should be <= 0) tensor(8.4844, device='cuda:0')\n",
      "layer 1 dim 98 descent(should be <= 0) tensor(25.3945, device='cuda:0')\n",
      "layer 1 dim 99 descent(should be <= 0) tensor(128.3516, device='cuda:0')\n",
      "layer 1 dim 99 descent(should be <= 0) tensor(127.9531, device='cuda:0')\n",
      "layer 1 dim 99 descent(should be <= 0) tensor(128.5000, device='cuda:0')\n",
      "layer 1 dim 101 descent(should be <= 0) tensor(410.5312, device='cuda:0')\n",
      "layer 1 dim 101 descent(should be <= 0) tensor(410.5938, device='cuda:0')\n",
      "layer 1 dim 101 descent(should be <= 0) tensor(408.7500, device='cuda:0')\n",
      "Layer 0: reached maximum number of iterations for line search\n",
      "layer 1 dim 118 descent(should be <= 0) tensor(4.0625, device='cuda:0')\n",
      "layer 1 dim 132 descent(should be <= 0) tensor(266.0156, device='cuda:0')\n",
      "layer 1 dim 133 descent(should be <= 0) tensor(119.8984, device='cuda:0')\n",
      "layer 1 dim 135 descent(should be <= 0) tensor(1.2061, device='cuda:0')\n",
      "layer 1 dim 145 descent(should be <= 0) tensor(4.6719, device='cuda:0')\n",
      "layer 1 dim 147 descent(should be <= 0) tensor(36.7856, device='cuda:0')\n",
      "layer 1 dim 154 descent(should be <= 0) tensor(13.3164, device='cuda:0')\n",
      "layer 1 dim 159 descent(should be <= 0) tensor(13.8242, device='cuda:0')\n",
      "layer 1 dim 159 descent(should be <= 0) tensor(13.8438, device='cuda:0')\n",
      "layer 1 dim 159 descent(should be <= 0) tensor(13.7422, device='cuda:0')\n",
      "layer 1 dim 160 descent(should be <= 0) tensor(0.6455, device='cuda:0')\n",
      "layer 1 dim 165 descent(should be <= 0) tensor(5.5488, device='cuda:0')\n",
      "layer 1 dim 166 descent(should be <= 0) tensor(32.7812, device='cuda:0')\n",
      "layer 1 dim 166 descent(should be <= 0) tensor(32.5938, device='cuda:0')\n",
      "layer 1 dim 166 descent(should be <= 0) tensor(32.9062, device='cuda:0')\n",
      "layer 1 dim 176 descent(should be <= 0) tensor(11.5938, device='cuda:0')\n",
      "layer 1 dim 176 descent(should be <= 0) tensor(11.7051, device='cuda:0')\n",
      "layer 1 dim 176 descent(should be <= 0) tensor(11.4375, device='cuda:0')\n",
      "layer 1 dim 179 descent(should be <= 0) tensor(4.3418, device='cuda:0')\n",
      "layer 1 dim 193 descent(should be <= 0) tensor(67.7793, device='cuda:0')\n",
      "layer 1 dim 197 descent(should be <= 0) tensor(5.1406, device='cuda:0')\n",
      "layer 1 dim 202 descent(should be <= 0) tensor(6.1951, device='cuda:0')\n",
      "layer 1 dim 208 descent(should be <= 0) tensor(1.8633, device='cuda:0')\n",
      "layer 1 dim 208 descent(should be <= 0) tensor(1.8223, device='cuda:0')\n",
      "layer 1 dim 220 descent(should be <= 0) tensor(14.2969, device='cuda:0')\n",
      "layer 1 dim 222 descent(should be <= 0) tensor(2.2134, device='cuda:0')\n",
      "layer 1 dim 235 descent(should be <= 0) tensor(2.8989, device='cuda:0')\n",
      "layer 1 dim 236 descent(should be <= 0) tensor(0.8359, device='cuda:0')\n",
      "layer 1 dim 237 descent(should be <= 0) tensor(1.8857, device='cuda:0')\n",
      "layer 1 dim 238 descent(should be <= 0) tensor(23.9062, device='cuda:0')\n",
      "layer 1 dim 238 descent(should be <= 0) tensor(23.3438, device='cuda:0')\n",
      "layer 1 dim 238 descent(should be <= 0) tensor(23.7188, device='cuda:0')\n",
      "layer 1 dim 245 descent(should be <= 0) tensor(117.3906, device='cuda:0')\n",
      "layer 1 dim 272 descent(should be <= 0) tensor(6.4985, device='cuda:0')\n",
      "layer 1 dim 275 descent(should be <= 0) tensor(1.1152, device='cuda:0')\n",
      "layer 1 dim 282 descent(should be <= 0) tensor(8.8711, device='cuda:0')\n",
      "layer 1 dim 282 descent(should be <= 0) tensor(8.8926, device='cuda:0')\n",
      "layer 1 dim 282 descent(should be <= 0) tensor(8.8984, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:11<00:56, 11.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 1 dim 294 descent(should be <= 0) tensor(1090.5000, device='cuda:0')\n",
      "layer 2 dim 62 descent(should be <= 0) tensor(9.4297, device='cuda:0')\n",
      "layer 2 dim 63 descent(should be <= 0) tensor(2.4258, device='cuda:0')\n",
      "layer 2 dim 63 descent(should be <= 0) tensor(2.4189, device='cuda:0')\n",
      "layer 2 dim 63 descent(should be <= 0) tensor(2.4229, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:17<00:17,  5.95s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 98\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m     97\u001b[0m     w_h \u001b[38;5;241m=\u001b[39m WEIGHTS[layer_idx][h]\n\u001b[0;32m---> 98\u001b[0m     new_w_h \u001b[38;5;241m=\u001b[39m \u001b[43mw_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCACHE_RELUS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# rel_diff = torch.linalg.norm(new_w_h-w_h) / torch.linalg.norm(w_h)\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# print(f'layer_idx {layer_idx}, h: {h}, it: {it}, REL_DIFF: {rel_diff}')\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     WEIGHTS[layer_idx][h] \u001b[38;5;241m=\u001b[39m new_w_h\n",
      "Cell \u001b[0;32mIn[15], line 36\u001b[0m, in \u001b[0;36mw_step\u001b[0;34m(w_h, layer_idx, h, n_samples, x, CACHE_RELUS)\u001b[0m\n\u001b[1;32m     33\u001b[0m residuals \u001b[38;5;241m=\u001b[39m w_residuals(w_h, layer_idx, h, x, CACHE_RELUS)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Building Jacobian (for each layer and output dim)\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m J \u001b[38;5;241m=\u001b[39m \u001b[43mw_jacob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCACHE_RELUS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCACHE_RELUS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# why not inversion here?\u001b[39;00m\n\u001b[1;32m     39\u001b[0m p \u001b[38;5;241m=\u001b[39m bk\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mlstsq(J\u001b[38;5;241m.\u001b[39mT\u001b[38;5;129m@J\u001b[39m, \u001b[38;5;241m-\u001b[39m J\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m residuals, rcond\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[15], line 25\u001b[0m, in \u001b[0;36mw_jacob\u001b[0;34m(w_h, layer_idx, n_samples, x, CACHE_RELUS)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_samples):\n\u001b[0;32m---> 25\u001b[0m         J[n, :] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m-\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msquare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtanh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCACHE_RELUS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mw_h\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mCACHE_RELUS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     27\u001b[0m plt\u001b[38;5;241m.\u001b[39mspy(J\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m J\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_loader, test_loader = get_train_test_dataloaders('..', 'USPS', \n",
    "                                                       batch_size=batch_size, \n",
    "                                                       drop_last=False,\n",
    "                                                       num_workers=4)\n",
    "for x, _ in train_loader:\n",
    "    x = x.to(device)\n",
    "    break\n",
    "\n",
    "relu = nn.ReLU()\n",
    "\n",
    "line_search_c = pow(10,-4)\n",
    "# backtracking multiplier\n",
    "line_search_tau = 0.5\n",
    "\n",
    "# Quadratic Penalty multiplier \n",
    "mu = 1.0\n",
    "\n",
    "loss_function = torch.nn.MSELoss()\n",
    "loss_hist = []\n",
    "\n",
    "# creating model\n",
    "model = AE_Tanh(bias=False).to(device)\n",
    "loss = eval_loss(model, test_loader, loss_function, device=device)\n",
    "loss_hist.append(loss)\n",
    "print(f'Random-initialized model loss: {loss}')\n",
    "\n",
    "WEIGHTS = [\n",
    "    model.encoder[0].weight.detach(),\n",
    "    model.encoder[2].weight.detach(),\n",
    "    model.encoder[4].weight.detach(),\n",
    "    model.decoder[0].weight.detach(),\n",
    "    model.decoder[2].weight.detach(),\n",
    "    model.decoder[4].weight.detach(),\n",
    "]\n",
    "\n",
    "# all output shapes\n",
    "h_k = [0]\n",
    "for W in WEIGHTS:\n",
    "    h_k.append(W.shape[0] + h_k[-1])\n",
    "h_k = h_k[1:-1]\n",
    "print(h_k)\n",
    "\n",
    "# # registering hooks to cache activations\n",
    "# CACHE_RELUS = {}\n",
    "\n",
    "# def cache_relu_hook(idx, module, input, output):\n",
    "#     CACHE_RELUS[idx] = output.detach().cpu()\n",
    "\n",
    "# i = 0 \n",
    "# for m in model.modules():\n",
    "#     if isinstance(m, nn.ReLU):\n",
    "#         handle = m.register_forward_hook(partial(cache_relu_hook, i))\n",
    "#         i += 1\n",
    "        \n",
    "# # caching activations\n",
    "# with torch.no_grad():\n",
    "#     for x, _ in train_loader:\n",
    "#         x = x.to(device)\n",
    "#         _ = model(x)\n",
    "#         x = x.detach().cpu()\n",
    "        \n",
    "# # Removing Hooks\n",
    "# for m in model.modules():\n",
    "#     if isinstance(m, nn.ReLU):\n",
    "#         m._forward_hooks = OrderedDict()\n",
    "\n",
    "n_samples = train_loader.batch_size\n",
    "# init z_n randomly\n",
    "CACHE_RELUS = {}\n",
    "for i, w in enumerate(WEIGHTS[:-1]):\n",
    "    # CACHE_RELUS[i] = bk.random.uniform(-0.5, 0.5, size=(n_samples, w.shape[0]))\n",
    "    CACHE_RELUS[i] = torch.rand((n_samples, w.shape[0]), device=device) - 0.5 \n",
    "        \n",
    "def _get_n_sample_relus(n_sample, cache):\n",
    "    n_sample_relus = torch.zeros(h_k[-1], device=device)\n",
    "    start = 0\n",
    "    for layer_idx in range(len(h_k)):\n",
    "        n_sample_relus[start:h_k[layer_idx]] = cache[layer_idx][n_sample]\n",
    "        start = h_k[layer_idx]\n",
    "    return n_sample_relus\n",
    "\n",
    "        \n",
    "with torch.no_grad():\n",
    "    for epoch in range(10):\n",
    "            \n",
    "        # W-Step\n",
    "        WEIGHTS_COPY = copy.deepcopy(WEIGHTS)\n",
    "\n",
    "        for layer_idx in tqdm(range(len(WEIGHTS))):\n",
    "\n",
    "            for h in range(WEIGHTS[layer_idx].shape[0]):\n",
    "                for it in range(3):\n",
    "                    w_h = WEIGHTS[layer_idx][h]\n",
    "                    new_w_h = w_step(w_h, layer_idx, h, n_samples, x, CACHE_RELUS)\n",
    "                    # rel_diff = torch.linalg.norm(new_w_h-w_h) / torch.linalg.norm(w_h)\n",
    "                    # print(f'layer_idx {layer_idx}, h: {h}, it: {it}, REL_DIFF: {rel_diff}')\n",
    "                    WEIGHTS[layer_idx][h] = new_w_h\n",
    "                    \n",
    "        # Checking Norm Difference\n",
    "        for layer_idx in range(len(WEIGHTS)):\n",
    "            print(f'Layer {layer_idx}, '\n",
    "                  f'Weights Diff Norm (%): {bk.linalg.norm(WEIGHTS[layer_idx]-WEIGHTS_COPY[layer_idx]) / bk.linalg.norm(WEIGHTS_COPY[layer_idx])}')\n",
    "        \n",
    "        # Loading weights back to model to compute eval loss\n",
    "        model.encoder[0].weight.data = WEIGHTS[0]\n",
    "        model.encoder[2].weight.data = WEIGHTS[1]\n",
    "        model.encoder[4].weight.data = WEIGHTS[2]\n",
    "        model.decoder[0].weight.data = WEIGHTS[3]\n",
    "        model.decoder[2].weight.data = WEIGHTS[4]\n",
    "        model.decoder[4].weight.data = WEIGHTS[5]\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Loss on eval dataset\n",
    "        loss = eval_loss(model, test_loader, loss_function, device=device)\n",
    "        loss_hist.append(loss)\n",
    "        print(f'Epoch {epoch+1}, Eval loss: {loss}')\n",
    "        \n",
    "        # # recalculating activations after weights update\n",
    "        # for x, _ in train_loader:\n",
    "        #     x = x.to(device)\n",
    "        #     _ = model(x)\n",
    "        #     x = x.cpu()\n",
    "    \n",
    "        # Z-Step\n",
    "        CACHE_RELUS_COPY = copy.deepcopy(CACHE_RELUS)\n",
    "        \n",
    "        # process for each sample\n",
    "        for n_sample in tqdm(range(n_samples)):\n",
    "            for it in range(1):\n",
    "                z_n = _get_n_sample_relus(n_sample, CACHE_RELUS)\n",
    "                J, new_z_n = z_step(z_n, n_sample, mu, h_k, x[n_sample], WEIGHTS)\n",
    "                start = 0\n",
    "                for layer_idx in range(len(h_k)):\n",
    "                    CACHE_RELUS[layer_idx][n_sample] = new_z_n[start:h_k[layer_idx]]\n",
    "                    start = h_k[layer_idx]\n",
    "                    \n",
    "                # rel_diff = torch.linalg.norm(new_z_n - z_n) / torch.linalg.norm(z_n)\n",
    "\n",
    "        # Computing Relus Norm Difference\n",
    "        for layer_idx in range(len(CACHE_RELUS)):\n",
    "            print(f'Layer {layer_idx} Activations Diff Norm (%): '\n",
    "                  f'{bk.linalg.norm(CACHE_RELUS[layer_idx]-CACHE_RELUS_COPY[layer_idx]) / bk.linalg.norm(CACHE_RELUS_COPY[layer_idx])}')\n",
    "            \n",
    "        # Updating Quandratic Penalty Multiplier\n",
    "        mu *= 1.5\n",
    "        \n",
    "        if epoch > 0 and epoch % 2 == 0: \n",
    "            with torch.no_grad():\n",
    "                y = model(x[:16].cuda())\n",
    "            plot_progress(x[:16], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad9bcd-f79f-47e6-a450-55e6a3a0fd21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7432d4ff-7b35-4fcb-a337-287b31e48586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d6e7dc-60ae-4f24-9692-68c52c363240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eve3",
   "language": "python",
   "name": "eve3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
